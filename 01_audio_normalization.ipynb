{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio normalization\n",
    "\n",
    "Audio can come in many formats, but the most common format when doing machine learning work is that we have audio in .wav files. These files contain a timeseries representing the audio, this timeseries is called the waveform. The amplitude of the timeseries represents the air pressure caused by the sound wave, you can read more about the waveform here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:audioprocessing]",
   "language": "python",
   "name": "conda-env-audioprocessing-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
